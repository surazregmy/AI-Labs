{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d3</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d4</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          d1        d2        d3        d4\n",
       "d1  1.000000  1.000000  0.100000  0.428571\n",
       "d2  1.000000  1.000000  0.100000  0.428571\n",
       "d3  0.100000  0.100000  1.000000  0.363636\n",
       "d4  0.428571  0.428571  0.363636  1.000000"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "def tokenize(text):\n",
    "    #remove full stops and question marks\n",
    "    #lower the text and split it by spaces.\n",
    "    text = text.replace(\".\", \"\")\n",
    "    text = text.replace(\",\", \"\")\n",
    "    return text.lower().split()\n",
    "\n",
    "def jaccard(first_document, second_document):\n",
    "    #calculate jaccard similarity\n",
    "    intersection = set(first_document).intersection(set(second_document))\n",
    "    union = set(first_document).union(set(second_document))\n",
    "    return len(intersection)/len(union)\n",
    "\n",
    "d1 = \"I am Sam.\"\n",
    "d2 = \"Sam I am.\"\n",
    "d3 = \"I do not like green eggs and ham.\"\n",
    "d4 = \"I do not like them, Sam I am.\"\n",
    "\n",
    "documents_list = [d1, d2, d3, d4]\n",
    "tokenized_documents = [tokenize(doc) for doc in documents_list] # tokenize all the documents\n",
    "\n",
    "jaccard_list = {} # dictionary to store all the documents' jaccard similarity to each other.\n",
    "\n",
    "# append the document index as the key of the dictionary.\n",
    "for index, doc in enumerate(documents_list):\n",
    "    for index, doc in enumerate(documents_list):\n",
    "        jaccard_list[index] = {}\n",
    "\n",
    "# create a nested dictionary where the nested dictionary holds the jaccard similarity between the documents.\n",
    "# ie. {0 : {0: ..., 1: ..., 2:..., 3:...}, 1: {0: ..., 1: ..., 2:..., 3:...} and so on}\n",
    "for first_doc_index, doc in enumerate(documents_list):\n",
    "    for second_doc_index, doc in enumerate(documents_list):\n",
    "        jaccard_list[first_doc_index][second_doc_index] = jaccard(tokenized_documents[first_doc_index], tokenized_documents[second_doc_index])\n",
    "\n",
    "\n",
    "# show the result in a table\n",
    "overall_matrix = pd.DataFrame(jaccard_list)\n",
    "overall_matrix.columns = ['d1', 'd2', 'd3', 'd4']\n",
    "overall_matrix.index = ['d1', 'd2', 'd3', 'd4']\n",
    "\n",
    "overall_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
